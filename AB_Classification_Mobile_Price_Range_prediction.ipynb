{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "Yfr_Vlr8HBkt",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaavyesh/Mobile-phone-price-prediction-classification/blob/main/AB_Classification_Mobile_Price_Range_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**  S.Kaavyesh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Summary:\n",
        "In a bid to decode the intricate dynamics governing mobile phone pricing, this project embarked on an in-depth analysis of a dataset containing an extensive array of attributes – approximately 21 variables. The primary objective was to predict the price range of mobile phones, categorized into distinct tiers, from low-cost to very high-end. The journey commenced with meticulous data wrangling, addressing missing values and anomalies that might taint the subsequent analyses. Through a robust exploratory data analysis (EDA) phase, the project unearthed intriguing insights into the interplay between mobile phone attributes and their price classifications.\n",
        "\n",
        "The project discovered intriguing correlations, notably the positive relationship between battery capacity and price range, shedding light on consumers' willingness to pay a premium for extended battery life. Similarly, RAM emerged as a pivotal determinant, with a clear upward trajectory linking it to higher price ranges. On the other hand, screen size exhibited consistent distribution across price categories, suggesting its relatively diminished role as the sole driver of price segmentation. Employing hypothesis testing, the project verified key statements and meticulously addressed outliers that could skew results.\n",
        "\n",
        "Capitalizing on the identified influential factors, the project ventured into feature engineering and deployed various machine learning models – including logistic regression, random forest, and XGBoost – to predict mobile phone price categories. After meticulous experimentation, it became evident that logistic regression and XGBoost, fortified with hyperparameter tuning, yielded the most accurate predictions"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:\n",
        "The fiercely competitive mobile phone industry witnesses price variations influenced by an array of factors like battery power, camera quality, screen dimensions, and more. A comprehensive study was undertaken to decipher the key determinants shaping the price categories of mobile phones, encompassing low, medium, high, and very high ranges. The investigation delved into data wrangling, exploratory data analysis (EDA), hypothesis testing, feature engineering, and machine learning modeling to unravel the intricate relationship between features and price ranges.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's gear up with the tools we need!\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Don't want any warnings cramping our style!\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the data set\n",
        "path = '/content/drive/MyDrive/classification /data_mobile_price_range.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "VXIKxWYvAIi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "#first 10 rows\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicated_count = df.duplicated().sum()\n",
        "duplicated_count"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull())"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Dimensions: The dataset comprises 21 columns and 2000 rows.\n",
        "\n",
        "Duplicates Detected: No replicated values exist in the dataset.\n",
        "\n",
        "Missing Values: The dataset is complete without any missing entries."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Battery Power (Battery_power): Total energy storage of the battery (mAh).\n",
        "\n",
        "Bluetooth (Blue): Presence of Bluetooth connectivity.\n",
        "\n",
        "Clock Speed (Clock_speed): Processor's execution speed.\n",
        "\n",
        "Dual SIM (Dual_sim): Support for dual SIM cards.\n",
        "\n",
        "Front Camera (Fc): Mega pixels of the front camera.\n",
        "\n",
        "4G (Four_g): Availability of 4G connectivity.\n",
        "\n",
        "Internal Memory (Int_memory): Gigabytes of internal memory.\n",
        "\n",
        "Mobile Depth (M_dep): Mobile phone depth in centimeters.\n",
        "\n",
        "Mobile Weight (Mobile_wt): Weight of the mobile phone.\n",
        "\n",
        "Processor Cores (N_cores): Number of processor cores.\n",
        "\n",
        "Primary Camera (Pc): Mega pixels of the primary camera.\n",
        "\n",
        "Pixel Resolution Height (Px_height): Pixel height of the display.\n",
        "\n",
        "Pixel Resolution Width (Px_width): Pixel width of the display.\n",
        "\n",
        "RAM (Ram): Random Access Memory in megabytes.\n",
        "\n",
        "Touch Screen (Touch_screen): Presence of a touch screen.\n",
        "\n",
        "Wi-Fi (Wifi): Availability of Wi-Fi connectivity.\n",
        "\n",
        "Screen Height (Sc_h): Mobile screen height in centimeters.\n",
        "\n",
        "Screen Width (Sc_w): Mobile screen width in centimeters.\n",
        "\n",
        "Talk Time (Talk_time): Longest battery life during a single charge.\n",
        "\n",
        "3G (Three_g): Availability of 3G connectivity.\n",
        "\n",
        "Price Range (Price_range): Target variable categorized into low, medium, high, and very high cost."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Unique values for {column}: {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Check and handle phones with sc_w = 0\n",
        "zero_sc_w_indices = df[df.sc_w == 0].index\n",
        "df.loc[zero_sc_w_indices, 'sc_w'] = df['sc_w'].mean()\n",
        "\n",
        "# Check and handle phones with px_height = 0\n",
        "zero_px_height_indices = df[df.px_height == 0].index\n",
        "df.loc[zero_px_height_indices, 'px_height'] = df['px_height'].mean()\n",
        "\n",
        "print(\"Zero values handled for sc_w and px_height\")\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero Values Found:** We spotted that 180 phones had zero pixel resolution height, and only 2 phones had a screen width of 0 cm.\n",
        "\n",
        "**Fixing Logic Lapse:** It doesn't make sense for a phone to have zero pixel height or screen width. So, we made things right by replacing these odd values with the average values of their respective attributes.\n",
        "\n",
        "**Ready for Analysis:**After these tweaks, our dataset is all set – no missing pieces and no illogical values – perfectly prepped for analysis!"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 price range distribution"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 1 visualization code\n",
        "\n",
        "#classes\n",
        "price_counts = df['price_range'].value_counts()\n",
        "plt.pie(price_counts, labels=price_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Price Range Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected this chart to understand how the percentage distribution of phones with low or high price ranges varies."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every price range category contains an evenly distributed number of phones."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " by analyzing the percentage distribution of phones, we've gained insights into their overall distribution patterns."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Battery Power"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(5,5)})\n",
        "\n",
        "# Create a histogram\n",
        "sns.histplot(data=df, x='battery_power', color='blue')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Battery Power')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Battery Power')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check whether the count rises with higher battery power values."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot illustrates the distribution of battery capacity (measured in mAh) across the dataset.\n",
        "\n",
        "Notably, there's a positive correlation between battery capacity and mobile phone price range. As the price range increases, the battery capacity tends to rise gradually.\n",
        "\n",
        "This suggests a strong relationship between battery capacity and phone price. Consumers appear inclined to pay more for phones with higher battery capacities."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "\n",
        "Manufacturers producing mobile phones with substantial battery capacity at a competitive cost can attract a larger customer base, boosting revenue through higher-priced models.\n",
        "\n",
        "This knowledge can guide marketing strategies, enabling companies to emphasize robust battery capacity as a compelling selling point, attracting potential customers.\n",
        "\n",
        "**Negative Growth Considerations:**\n",
        "\n",
        "The insights don't appear to lead to negative growth. However, it's important to acknowledge that focusing solely on battery capacity might overlook other influential factors in customer preferences, potentially affecting overall market competitiveness."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 Bluetooth"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(data=df, x='price_range', hue='blue', palette='Set2')\n",
        "plt.title('Bluetooth Presence vs. Price Range')\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the presence of Bluetooth in devices across different price ranges."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roughly 50% of the devices feature Bluetooth, while an equal number lack it."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Utilization:**\n",
        "\n",
        "Companies could potentially capitalize on the insight that around half of the devices possess Bluetooth and the other half don't. By strategically leveraging this data, businesses could enhance product offerings or marketing strategies.\n",
        "\n",
        "For instance, a mobile manufacturer might recognize the significance of Bluetooth to customers and thus prioritize Bluetooth-related features in their devices. This customer-centric approach can bolster brand appeal and attract more users.\n",
        "\n",
        "**Negative Pitfalls:**\n",
        "\n",
        "There's a risk if this insight is misinterpreted or mishandled. Suppose a company mistakenly assumes that Bluetooth isn't important because half the devices lack it. This viewpoint overlooks the fact that a significant portion of customers value Bluetooth functionality.\n",
        "\n",
        "Neglecting Bluetooth in device offerings could lead to missed sales and growth opportunities. This misstep might stem from an incomplete understanding of customer preferences and market dynamics."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 RAM"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map price ranges to colors\n",
        "color_map = {0: 'red', 1: 'blue', 2: 'green', 3: 'purple'}\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for price_range, color in color_map.items():\n",
        "    plt.scatter(df['price_range'][df['price_range'] == price_range],\n",
        "                df['ram'][df['price_range'] == price_range],\n",
        "                color=color, label=f'Price Range {price_range}')\n",
        "\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('RAM')\n",
        "plt.xticks([0, 1, 2, 3])\n",
        "plt.legend()\n",
        "plt.title('Price Range vs. RAM')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the relationship between price and RAM."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot vividly illustrates a strong positive relationship between RAM and price range.\n",
        "\n",
        "The bulk of data points cluster towards the upper right corner, indicating that devices with higher price ranges tend to possess more RAM.\n",
        "\n",
        "Essentially, as the price range ascends, the RAM capacity in the device tends to increase as well."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "The insights drawn from the scatter plot, notably the evident positive correlation between RAM and price range, hold substantial potential for businesses.\n",
        "\n",
        "This information enables companies to tailor their smartphone offerings, capitalizing on the customer segment willing to invest more for devices with greater RAM capacity.\n",
        "\n",
        "By designing and marketing smartphones catering to this trend, businesses could potentially amplify revenue and profits, creating a favorable impact.\n",
        "\n",
        "**Negative Growth Considerations:**\n",
        "\n",
        " it's essential to be cautious in the interpretation. Overemphasizing RAM without considering other crucial factors might lead to negative growth."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 dual_sim"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group data by price range and dual sim, and count the number of devices in each group\n",
        "sim_count = df.groupby(['price_range', 'dual_sim'])['dual_sim'].count().unstack()\n",
        "\n",
        "# Create a stacked bar chart\n",
        "sim_count.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Dual SIM Devices Count by Price Range')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand how the price range varies based on the usage of dual SIM"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trend appears consistent for low, medium, and high price ranges, showing similar distributions regardless of dual SIM usage."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "By understanding how the count of devices with dual SIM capability changes across price ranges, businesses can tailor their product offerings to align with customer preferences."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 Four_g"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Group data by price range and 4G SIM, and calculate the percentage of devices in each group\n",
        "fourg_percentage = df.groupby(['price_range', 'four_g'])['four_g'].count().unstack() / df.groupby('price_range')['price_range'].count()[:, None] * 100\n",
        "\n",
        "# Create a stacked percentage bar chart\n",
        "fourg_percentage.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Percentage of 4G SIM Devices by Price Range')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the percentage of 4G sim of mobile phones."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At low (0), medium (1), and very high (3) price ranges, mobile phones with SIM are more numerous. However, at the high (2) price range, there's a slight decline in the prevalence of phones with SIM cards."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "armed with this insight, businesses can decide whether their target audience prefers single or dual SIM phones within a given price range, thereby enhancing product-market fit.\n",
        "\n",
        "**Negative Growth Considerations:**\n",
        "\n",
        "The observed slight decline in SIM card prevalence at higher price ranges could pose a challenge for companies heavily focused on dual SIM offerings."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 pixel_width"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot the KDE plot for pixel width distribution by price range\n",
        "sns.kdeplot(data=df, x='px_width', hue='price_range', fill=True, common_norm=False, palette='viridis', ax=axs[0])\n",
        "axs[0].set_xlabel('Pixel Width')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Width Distribution by Price Range')\n",
        "\n",
        "# Plot the box plot of pixel width by price range\n",
        "sns.boxplot(data=df, x='price_range', y='px_width', palette='viridis', ax=axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Width')\n",
        "axs[1].set_title('Pixel Width by Price Range')\n",
        "\n",
        "# Adjust the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Create a kernel density estimate plot for the pixel height distribution for each price range\n",
        "sns.kdeplot(data=df, x='px_height', hue='price_range', fill=True, common_norm=False, palette='viridis', ax=axs[0])\n",
        "axs[0].set_xlabel('Pixel Height')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Height Distribution by Price Range')\n",
        "\n",
        "# Create a box plot of pixel height for each price range\n",
        "sns.boxplot(data=df, x='price_range', y='px_height', palette='viridis', ax=axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Height')\n",
        "axs[1].set_title('Pixel Height by Price Range')\n",
        "\n",
        "# Adjust the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_gjBODxu1AfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the pixel width on the price range."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-Linear Pixel Width Trend: Pixel width doesn't consistently increase with higher prices. Medium and high-cost phones share similar pixel width, indicating it's not the sole price determinant.\n",
        "\n",
        "Pixel Height Consistency: Pixel height maintains a similar pattern across different cost ranges, with minimal variation. This highlights pricing complexity and the need to consider various factors for effective market strategies."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "Insights from the pixel height distribution analysis offer significant value to mobile phone manufacturers and marketers. Understanding the connection between pixel height and price range empowers manufacturers to refine product design and pricing, fostering improved sales.\n",
        "\n",
        "Marketers, too, can leverage this knowledge to craft targeted advertising campaigns and promotions tailored to distinct consumer preferences. This alignment can enhance brand resonance and consumer engagement.\n",
        "\n",
        "**Negative Growth Considerations:**\n",
        "\n",
        "The limited pixel height variation across price ranges could potentially challenge manufacturers and marketers. If pixel height lacks substantial influence on price categorization, companies must pivot towards other vital attributes like processor efficiency, camera excellence, storage capacity, and brand appeal."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 FC (front camera megapixels)"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a boxplot of front camera megapixels grouped by price range\n",
        "sns.boxplot(x='price_range', y='fc', data=df)\n",
        "\n",
        "# set x and y axis labels and title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Front Camera Megapixels')\n",
        "plt.title('Front Camera Megapixels vs Price Range')\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the impact of price range on front camera megapixels."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The impact of price range appears consistent across all categories."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "While the similarity in front camera megapixel distribution across price ranges may not directly guide pricing decisions, it has the potential to create a positive business impact.\n",
        "\n",
        "This insight can encourage manufacturers to shift their focus towards a more comprehensive approach, incorporating a range of features into their pricing strategies. By doing so, they can tailor products more precisely to customer preferences, boosting overall customer satisfaction and driving growth.\n",
        "\n",
        "**Negative Growth Considerations:**\n",
        "\n",
        "Relying solely on front camera megapixels for pricing determination might lead to negative growth. If competitors offer more advanced features that customers prioritize, a business could lose market share and growth opportunities."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 PC (Primary camera Megapixels)"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots side-by-side\n",
        "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
        "\n",
        "# Create a kernel density estimation plot of the distribution of number of cores across price ranges\n",
        "sns.kdeplot(data=df, x='n_cores', hue='price_range', ax=axs[0])\n",
        "\n",
        "# Create a box plot of the distribution of number of cores for each price range\n",
        "sns.boxplot(data=df, x='price_range', y='n_cores', ax=axs[1])\n",
        "\n",
        "# Set the title of the first subplot and the labels of both subplots\n",
        "axs[0].set_title('Distribution of Number of Cores by Price Range')\n",
        "axs[0].set_xlabel('Number of Cores')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[1].set_title('Number of Cores by Price Range')\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Number of Cores')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the distribution of number of cores by price range and number of cores by price range"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary camera megapixels' consistent distribution across various target categories implies that this attribute may not considerably impact mobile phone price ranges. This consistency is advantageous for prediction models, as it suggests that this feature might not be a substantial variable affecting price range prediction."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Strategic Resource Allocation: With the understanding that primary camera megapixels might not significantly influence price ranges, companies can allocate resources more strategically. Instead of disproportionately focusing on just camera features, they can balance investments across a spectrum of attributes that collectively contribute to consumer satisfaction."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "correlation = df.corr()\n",
        "\n",
        "plt.figure(figsize=[20, 15])\n",
        "sns.heatmap(correlation, cmap='viridis', annot=True, annot_kws={'fontsize': 10})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the multi-collinearity."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**High RAM-Price Range Correlation:**\n",
        "\n",
        "The substantial positive correlation observed between RAM and price_range is a favorable indication for businesses. This correlation implies that the amount of RAM is a pivotal determinant in estimating a mobile phone's price range.\n",
        "Collinearity and Feature Pairs:\n",
        "\n",
        "Some instances of collinearity exist within the dataset. Notably, the features ('pc', 'fc') and ('px_width', 'px_height') exhibit correlations. These correlations are sensible, as a mobile phone equipped with a strong front camera is likely to have a commendable primary camera. Similarly, an increase in pixel height often corresponds to an increase in pixel width."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant relationship between battery power and price range.\n",
        "Alternative Hypothesis (H1): There is a significant relationship between battery power and price range."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Calculate the correlation coefficient and p-value\n",
        "correlation, p_value = pearsonr(df['battery_power'], df['price_range'])\n",
        "\n",
        "# Define the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results\n",
        "print(f\"Correlation coefficient: {correlation}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: There is a significant relationship between battery power and price range.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: There is no significant relationship between battery power and price range.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the p-value, I used the Pearson correlation coefficient test. The Pearson correlation coefficient measures the linear relationship between two continuous variables. The p-value obtained from this test helps determine whether the observed correlation is statistically significant or occurred by chance."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the Pearson correlation coefficient test as the specific statistical test because it is suitable for assessing the strength and direction of the linear relationship between two continuous variables. In this case, we were examining the relationship between battery power (a continuous variable) and price range (which can be treated as an ordinal variable)."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant association between the presence of 4G connectivity and price range.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant association between the presence of 4G connectivity and price range."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(df['four_g'], df['price_range'])\n",
        "\n",
        "# Perform the chi-square test\n",
        "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Define the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-square statistic: {chi2}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: There is a significant association between 4G connectivity and price range.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: There is no significant association between 4G connectivity and price range.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test of independence is used to determine if there is a significant association between two categorical variables. In this case, we were examining the association between the categorical variable \"four_g\" (presence or absence of 4G connectivity) and the ordinal variable \"price_range\" (different price ranges)."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the chi-square test of independence as the specific statistical test because it's suitable for assessing the association between two categorical variables, such as the presence of 4G connectivity (categorical) and the price range (ordinal) of mobile phones in this case."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the mean RAM between low-cost and high-cost mobile phones.\n",
        "Alternative Hypothesis (H1): There is a significant difference in the mean RAM between low-cost and high-cost mobile phones."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Extract RAM values for low-cost and high-cost phones\n",
        "ram_low_cost = df[df['price_range'] == 0]['ram']\n",
        "ram_high_cost = df[df['price_range'] == 2]['ram']\n",
        "\n",
        "# Perform the independent t-test\n",
        "t_statistic, p_value = ttest_ind(ram_low_cost, ram_high_cost)\n",
        "\n",
        "# Define the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: There is a significant difference in the mean RAM between low-cost and high-cost mobile phones.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: There is no significant difference in the mean RAM between low-cost and high-cost mobile phones.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used an independent two-sample t-test to obtain the p-value for the hypothesis testing related to the difference in the mean RAM between low-cost and high-cost mobile phones.\n",
        "\n",
        "The independent t-test is used when comparing means of two independent samples to determine if there is a statistically significant difference between them. In this case, we were comparing the mean RAM of two groups: low-cost mobile phones and high-cost mobile phone"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the independent two-sample t-test as the specific statistical test for hypothesis testing because it's appropriate for comparing the means of two independent groups, which is exactly what we wanted to assess in this scenario: the difference in mean RAM between low-cost and high-cost mobile phones."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No missing value available"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Set the figure size to 20x20\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "# Get a list of column names from the DataFrame's describe() method\n",
        "column_names = df.describe().columns.tolist()\n",
        "\n",
        "# Loop through each column and create a subplot\n",
        "for index, column in enumerate(column_names):\n",
        "\n",
        "    # Create a subplot in a 5x5 grid\n",
        "    plt.subplot(5, 5, index + 1)\n",
        "\n",
        "    # Create a box plot of the current column's data\n",
        "    sns.boxplot(data=df, x=column)\n",
        "\n",
        "    # Add the column name to the subplot title\n",
        "    plt.title(column)\n",
        "\n",
        "    # Add some spacing between the subplots\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Display the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their is no much outliers are present no need to do much experiment."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding not necessary beacause all values are present in integer or float."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "# Transform Your data\n",
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Defining X and y\n",
        "df.drop(['px_height', 'px_width'], axis = 1, inplace = True)\n",
        "\n",
        "X = df.drop(['price_range'], axis = 1)\n",
        "y = df['price_range']\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it is important i have deopped px_height and px_width which dont have any use."
      ],
      "metadata": {
        "id": "hu6ZtCGRJ4fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Scaling values of X\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is using MinMaxScaler from the Scikit-learn library to scale the data in X. This method scales the data such that it is within a specified range, typically between 0 and 1. It does this by subtracting the minimum value from each data point and then dividing by the range (the difference between the maximum and minimum values).\n",
        "\n",
        "MinMaxScaler is a commonly used scaling method in machine learning, particularly when the distribution of the data is unknown or non-normal, as it can handle both of these cases well. It is also useful when there are outliers in the data, as it is less affected by them than other scaling methods."
      ],
      "metadata": {
        "id": "CUQiGwTeKEve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X = df.drop(['price_range'], axis = 1)\n",
        "y = df['price_range']\n",
        "# Splitting dataset into train and test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is using a data splitting ratio of 80:20 for the training and test sets, respectively, as specified by the test_size parameter set to 0.20. This means that 80% of the data will be used for training the model, and 20% of the data will be used for testing the model's performance.\n",
        "\n",
        "This is a common splitting ratio used in machine learning, where a larger proportion of the data is used for training to ensure the model has enough data to learn from. The smaller proportion of data allocated for testing is used to evaluate the model's performance on unseen data, which helps to assess how well the model is generalizing to new data.\n",
        "\n",
        "The random_state parameter is set to 42, which is an arbitrary number used to ensure that the data is split in a reproducible way. The same random state value can be used across different runs of the code to ensure that the same data points are assigned to the training and test sets each time."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1  LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Applying logistic regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Prediction\n",
        "\n",
        "y_pred_test = lr.predict(X_test)\n",
        "y_pred_train = lr.predict(X_train)\n",
        "\n",
        "\n",
        "# Classification report for Test Set\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Test set)= ')\n",
        "print(classification_report(y_pred_test, y_test))\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for Training Set\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Train set)= ')\n",
        "print( classification_report(y_pred_train, y_train))"
      ],
      "metadata": {
        "id": "UOZnf44YLCck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall accuracy of the model on the training set is 83%.\n",
        "\n",
        "Precision for class 0 (low cost) is 93%, meaning it's accurate when predicting class 0.\n",
        "\n",
        "Recall for class 0 is 88%, indicating it identifies 88% of actual class 0 instances.\n",
        "\n",
        "F1-score for class 0 is 90%, representing a balance between precision and recall.\n",
        "\n",
        "Similar precision, recall, and F1-score scores are shown for classes 1, 2, and 3.\n",
        "\n",
        "Macro average of precision, recall, and F1-score is 83%, providing an unweighted mean.\n",
        "\n",
        "Weighted average of precision, recall, and F1-score is also 83%, accounting for class distribution."
      ],
      "metadata": {
        "id": "wF2em0zeLWkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 1\n",
        "# Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "scores = cross_val_score(lr, X_scaled, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", np.mean(scores))\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(lr, param_grid, cv=5)\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"Best cross-validation score:\", grid.best_score_)\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Test set score:\", grid.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "diJDhIFmLeeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is a widely used method for hyperparameter tuning.\n",
        "\n",
        "It involves searching over a predefined grid of hyperparameters.\n",
        "\n",
        "The goal is to find the best hyperparameter combination for optimal performance.\n",
        "\n",
        "Hyperparameters are parameters that control the behavior of the model.\n",
        "\n",
        "In this case, GridSearchCV explored various values of C, which controls regularization strength.\n",
        "\n",
        "The technique exhaustively searches the entire grid for the best-performing combination.\n",
        "\n",
        "GridSearchCV helps in improving the model's performance by fine-tuning hyperparameters."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best cross-validation score achieved was 0.82, and the best hyperparameter value for C was found to be 10.\n",
        "\n",
        "After training the model with the best hyperparameters, the test set score was also found to be 0.82. This suggests that the model is performing consistently well on both the training and test sets, and that it is unlikely to be overfitting.\n",
        "\n",
        "Overall, it appears that the logistic regression model with the selected hyperparameters is a good fit for the dataset, achieving an accuracy score of 0.82 on the test set. However, it would be useful to also consider other evaluation metrics such as precision, recall, and F1-score to get a more complete understanding of the model's performance.."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2  XGBOOST"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying XGBoost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(max_depth = 5, learning_rate = 0.1)\n",
        "xgb.fit(X_train, y_train)\n",
        "XGBClassifier(max_depth=5, objective='multi:softprob')\n",
        "\n",
        "# Prediction\n",
        "y_pred_train = xgb.predict(X_train)\n",
        "y_pred_test = xgb.predict(X_test)\n",
        "\n",
        "# Evaluation metrics for Test set\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for Training Set\n",
        "\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for XGBoost(Train set)= ')\n",
        "print(score)\n"
      ],
      "metadata": {
        "id": "IEt3jzohMEp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBoost model on the training set, it achieved a very high accuracy score of 0.99. The precision, recall, and F1-score for each class are also very high, ranging from 0.99 to 1.00, which indicates that the model is performing very well on the training set.\n",
        "\n",
        "The macro average and weighted average F1-scores are also very high, indicating that the model is able to generalize well to all the classes and that it is not biased towards any particular class.\n",
        "\n",
        "Overall, the XGBoost model appears to be performing extremely well on the training set, achieving near-perfect scores across all evaluation metrics. However, it is important to also evaluate the model's performance on the test set to ensure that it is not overfitting to the training data."
      ],
      "metadata": {
        "id": "R27_h-g-MKon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define the XGBoost classifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "params = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "}\n",
        "\n",
        "# Perform cross-validation and hyperparameter tuning\n",
        "grid_search = GridSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and CV score\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the tuned model on the test set\n",
        "y_pred_test = grid_search.predict(X_test)\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)\n",
        ""
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_wzckhKMY50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for tuned XGBoost(Train set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "zr11cmNEWcVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've employed the GridSearchCV technique for optimizing hyperparameters. GridSearchCV is a widely utilized approach for tuning hyperparameters. It exhaustively explores a predefined set of hyperparameter values for an estimator, evaluating each combination through cross-validation. GridSearchCV automates the parameter tuning process and aids in identifying the optimal hyperparameter combination for the model, ultimately enhancing its performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, there's noticeable enhancement in the XGBoost model's performance post hyperparameter tuning and cross-validation. The cross-validation score rose from 0.815 to 0.81, and there were slight improvements in precision, recall, and f1-score for each class in the test set classification report. Moreover, the tuned XGBoost model's classification report for the training set retained its high performance level. While the improvements are moderate, they signify a better ability of the model to generalize to new data."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision: Precision gauges the accuracy of positive predictions made by the model, measured as the ratio of true positive predictions to the total positive predictions. In our case, it indicates the accuracy of the model's price range predictions for mobile phones. High precision is crucial when mistaking positives can be costly, like predicting a phone to be pricier than it is, potentially deterring customers.\n",
        "\n",
        "Recall: Recall assesses the model's ability to correctly identify all positive instances by calculating the ratio of true positive predictions to the total actual positive instances. In our context, it measures how well the model recognizes mobile phones within specific price ranges. High recall is vital when missing positives can be costly, like predicting a phone to be cheaper than it is, resulting in revenue loss.\n",
        "\n",
        "F1-score: F1-score balances precision and recall by taking their harmonic mean. It's a versatile metric for evaluating overall model performance when both precision and recall matter. For us, F1-score provides an encompassing assessment of the model's ability to accurately classify price ranges.\n",
        "\n",
        "These metrics collectively help gauge the model's accuracy, false predictions, and overall effectiveness. A well-performing model can greatly benefit a business by enhancing efficiency, cutting costs, and boosting revenue. In the mobile phone pricing scenario, an accurate model aids in setting optimal prices, driving revenue growth and customer contentment."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3  Random Forest classifier"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 3 Implementation\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# taking 300 trees\n",
        "clsr = RandomForestClassifier(n_estimators=300)\n",
        "clsr.fit(X_train, y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = clsr.predict(X_test)\n",
        "test_score= accuracy_score(y_test, y_pred)\n",
        "test_score\n",
        ""
      ],
      "metadata": {
        "id": "sdHsL-arboBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = clsr.predict(X_train)\n",
        "train_score = accuracy_score(y_train, y_pred_train)\n",
        "train_score"
      ],
      "metadata": {
        "id": "1fePANvkbrfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report for Test Set\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "gE38NXrFbxcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VwruPGKwbzCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FEATURES STORED**"
      ],
      "metadata": {
        "id": "TitmFTnncZLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "-QLcuolkcREW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D8zwH01ucUaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classification was done using a Random Forest model. From the evaluation metrics, we can deduce that the model's accuracy stands at 80%, indicating 80% of the predictions are accurate. Precision for class 0 is 92%, implying that 92% of positive predictions for class 0 are correct. The model's recall for class 1 is 76%, signifying that it correctly identified 76% of actual positive instances in class 1. The F1-score for class 2 is 68%, providing an overall accuracy measure considering both precision and recall.\n",
        "\n",
        "In summary, the Random Forest model exhibits moderate performance in this classification, with metrics such as accuracy, precision, recall, and F1-score varying between 63% and 92% depending on the class being predicted."
      ],
      "metadata": {
        "id": "_gvOW-t4c0sF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'n_estimators':[10,50,100,200],\n",
        "          'max_depth':[10,20,30,40],\n",
        "           'min_samples_split':[2,4,6],\n",
        "          'max_features':['sqrt',4,'log2','auto'],\n",
        "          'max_leaf_nodes':[10, 20, 40]\n",
        "          }\n",
        "rf = RandomForestClassifier()\n",
        "clsr = GridSearchCV(rf, params, scoring='accuracy', cv=3)\n",
        "clsr.fit(X, y)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_params_"
      ],
      "metadata": {
        "id": "NvaA-uaOfA1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_estimator_"
      ],
      "metadata": {
        "id": "L-9leUWyfHlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_score_"
      ],
      "metadata": {
        "id": "WJqDn4HbfMW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wB4pm5s3fQKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "clsr = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=30, max_features='log2',\n",
        "                       max_leaf_nodes=40, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=4,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "clsr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "eUQptccCfVIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score for Training set\n",
        "y_pred = clsr.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "metadata": {
        "id": "nUBnl-x4fZaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "anrYNQqWfjCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score for Test set\n",
        "y_pred = clsr.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "2lWRz2spfllu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "K2zlou3ofqhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FEATURES STORED**"
      ],
      "metadata": {
        "id": "mJkjSbzBf0hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "o_Ov21nQfxyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xpy7PBBDfyd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I employed the GridSearchCV technique for optimizing hyperparameters. GridSearchCV is a widely utilized method for fine-tuning hyperparameters. It exhaustively explores a predetermined range of hyperparameter values for an estimator, assessing each combination through cross-validation. This technique streamlines the parameter tuning process and identifies the optimal hyperparameter configuration, subsequently enhancing the model's performance."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " the model's performance has witnessed enhancement. The accuracy has seen a rise from 0.80 to 0.81, along with an increase in the weighted average F1-score from 0.80 to 0.81. While there is a marginal improvement in the precision and recall scores for most classes, except class 1, the macro average precision and recall scores have remained consistent. Collectively, the model's performance has undergone a slight improvement."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different evaluation metrics are utilized in the classification report to assess the model's performance. These metrics include precision, recall, and F1-score, both for individual classes and averages. Here are some key evaluation metrics that can have a positive business impact:\n",
        "\n",
        "Weighted Average of Precision, Recall, and F1-score: This metric factors in class imbalances by weighing the metrics according to the number of samples in each class. In the context of predicting mobile price ranges, this weighted average offers an overall assessment of the model's performance, considering the significance of each class.\n",
        "\n",
        "Macro Average of Precision, Recall, and F1-score: This metric computes the average precision, recall, and F1-score across all classes without considering class imbalances. For mobile price range prediction, the macro average helps evaluate the model's performance on each class individually and identifies challenging classes to predict.\n",
        "\n",
        "Confusion Matrix: The confusion matrix presents valuable insights into misclassifications and their underlying reasons. This aids in understanding which classes are commonly mispredicted and why, enabling potential refinements in the model or business strategies."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for logistic regression and XGBoost models due to their superior predictive capabilities compared to the random forest regression model."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can explain the logistic regression and XGBoost models and feature importance using a model explainability tool.\n",
        "\n",
        "Logistic regression is a linear classification algorithm that models the probability of a binary outcome (in this case, the mobile phone price range) as a function of the input features. It uses a logistic function to convert the linear function output to a probability value. The logistic regression model can be interpreted as the effect of each feature on the probability of a mobile phone belonging to a certain price range.\n",
        "\n",
        "XGBoost, on the other hand, is a powerful tree-based ensemble learning algorithm that uses a series of decision trees to make predictions. It works by iteratively adding decision trees to the ensemble, where each new tree is trained to correct the errors made by the previous ones. XGBoost can handle both regression and classification problems and is known for its high accuracy and robustness.\n",
        "\n",
        "To explain the feature importance of the logistic regression and XGBoost models, we can use the SHAP (SHapley Additive exPlanations) model explainability tool. SHAP values are a unified measure of feature importance that can be used to explain the output of any machine learning model. They are based on the Shapley value from cooperative game theory and provide a way to allocate the contribution of each feature to the final prediction. paraphrase it make it sound  a professional"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on our exploratory data analysis (EDA), we have uncovered several key insights about the mobile phones within our dataset. These observations shed light on the distinctive characteristics of various price ranges for these devices:\n",
        "\n",
        "**Price Range Distribution:** We identified that the dataset neatly categorizes mobile phones into four distinct price ranges, each containing a comparable number of entries. This balanced distribution ensures a well-rounded representation of different price segments.\n",
        "\n",
        "**Bluetooth Usage:** Our analysis revealed an even split, with approximately half of the devices featuring Bluetooth functionality and the other half lacking it. This balanced distribution of Bluetooth-enabled and non-enabled devices is noteworthy.\n",
        "\n",
        "**Battery Power and RAM:** As we ascend through the price ranges, we noticed a consistent upward trend in both battery power and RAM capacity. This suggests a positive correlation between these attributes and the price of mobile phones.\n",
        "\n",
        "**Weight Variation:** Interestingly, we found that higher-priced mobile phones tend to exhibit lighter weights compared to their lower-priced counterparts. This inverse relationship between price and weight might reflect design considerations or the use of premium materials.\n",
        "\n",
        "In the context of predicting mobile phone price ranges, our experiments highlighted the significance of certain attributes:\n",
        "\n",
        "**RAM, Battery Power, and Pixel Quality:** Through our analyses, we established that RAM, battery power, and pixel quality are pivotal factors in determining the price range of mobile phones. These attributes demonstrate substantial influence over the categorization of devices into different price segments.\n",
        "Our predictive modeling efforts led us to a meaningful conclusion:\n",
        "\n",
        "**Best Performing Algorithms:** Following rigorous experimentation and hyperparameter tuning, we determined that the logistic regression and XGBoost algorithms outperformed other models in predicting mobile phone price ranges. This conclusion underscores the efficacy of these methods in capturing the intricate relationships within our data.\n",
        "\n",
        "In essence, our exploratory data analysis has illuminated the division of mobile phones into well-balanced price ranges, showcased the prevalence of Bluetooth usage, and highlighted the impact of RAM, battery power, and pixel quality on price. Moreover, our predictive modeling endeavors underscore the efficacy of logistic regression and XGBoost algorithms, backed by hyperparameter tuning, in accurately predicting mobile phone price ranges."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}